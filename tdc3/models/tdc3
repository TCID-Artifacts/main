#!/bin/bash

mkdir tokenized_input

DIR_CSV=./input/
DIR_JSON=./tokenized_input/
CSV_file="${DIR_CSV}$(ls $DIR_CSV)"

# tokenize the test body
cd ../data/tokenizer/ && npm install && ./load ../../models/$DIR_CSV/ ../../models/$DIR_JSON/
cd ../../models 

export PYTHONPATH=$(pwd)

python3 py/main/Tdc3.py --CSV_file $CSV_file --JSON_dir $DIR_JSON --description_embedding ../data/embedded/description/embeddingModel --test_embedding ../data/embedded/test/embeddingModel --classification_model $(pwd)/final_model --max_body_length 60 --max_description_length 10